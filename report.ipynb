{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "results = {}\n",
    "with open('./results.json', 'r', encoding='utf-8') as f:\n",
    "    results = json.load(f)\n",
    "    \n",
    "codigos = results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# result = { \n",
    "#     \"pontuacao\" : None,\n",
    "#     \"n_subtarefas\" : None,\n",
    "#     \"subtarefas100\" : None,\n",
    "#     \"tempo_lim\" : None,\n",
    "#     \"mem_lim\" : None,\n",
    "#     \"tempo\" : None,\n",
    "#     \"mem\" : None,\n",
    "#     \"comp\" : None,\n",
    "#     \"stderr\" : None \n",
    "# }\n",
    "list_error = []\n",
    "list_warning = []\n",
    "list_accepted = []\n",
    "list_TLE = []\n",
    "list_MLE = []\n",
    "for codigo in codigos:\n",
    "    data = results[codigo]\n",
    "    if not data[\"comp\"]:\n",
    "        list_error.append(codigo)\n",
    "        continue\n",
    "    if len(data[\"stderr\"])>1:\n",
    "        list_warning.append(codigo)\n",
    "    if data[\"pontuacao\"] == 100:\n",
    "        list_accepted.append(codigo)\n",
    "    if data[\"tempo\"] >= data[\"tempo_lim\"]:\n",
    "        list_TLE.append(codigo)\n",
    "    if data[\"mem\"] >= data[\"mem_lim\"]:\n",
    "        list_MLE.append(codigo)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    return len(re.findall(r'\\S+', text))\n",
    "def get_info(info, codigo):\n",
    "    info[codigo] = {\n",
    "        \"len_enunciado\": None,\n",
    "        \"len_entrada\": None,\n",
    "        \"len_saida\": None,\n",
    "        \"n_restricoes\": None,\n",
    "        \"n_exemplos\": None\n",
    "    }\n",
    "    text = ''\n",
    "    with open(f'./pratique/{codigo}/{codigo}.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    data = info[codigo]\n",
    "    sections = re.split(r'\\n\\s*Entrada\\s*\\n',text)\n",
    "    enunciado = ''.join(sections[:2])\n",
    "    data[\"len_enunciado\"] = count_words(enunciado)\n",
    "    n_exemplos = len(sections)-2\n",
    "    len_entrada = 0\n",
    "    len_saida = 0\n",
    "    if n_exemplos > 0:\n",
    "        for section in sections [2:]:\n",
    "            splitted = re.split(r'\\n\\s*Saída\\s*\\n',section) # verificado se existe string 'Saida' nos textos # verificado se as strings procuradas existem nos textos\n",
    "            entrada = splitted[0]\n",
    "            try:\n",
    "                saida = splitted[1]\n",
    "            except: # quebra em caso de entrada vazia\n",
    "                print(f'{codigo} com entrada vazia.')\n",
    "                return\n",
    "            if len(entrada.strip()) == 0 or len(saida.strip()) == 0:\n",
    "                print(f'{codigo} com entrada ou saida vazia.')\n",
    "                return\n",
    "            len_entrada += count_words(entrada)\n",
    "            len_saida += count_words(saida)\n",
    "        len_entrada /= n_exemplos\n",
    "        len_saida /= n_exemplos\n",
    "        data[\"len_entrada\"] = len_entrada\n",
    "        data[\"len_saida\"] = len_saida\n",
    "    data[\"n_exemplos\"] = n_exemplos\n",
    "    data[\"n_restricoes\"] = enunciado.count('≤')+enunciado.count('≥')\n",
    "info = {}\n",
    "for codigo in codigos:\n",
    "    get_info(info, codigo)\n",
    "\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios = {}\n",
    "def get_comentarios(comentarios, codigo):\n",
    "    with open(f'./pratique/{codigo}/{codigo}.cpp', 'r', encoding='utf-8') as f:\n",
    "        code = f.read()\n",
    "    search = re.findall(r'(//.*?$|/\\*.*?\\*/)', code, re.DOTALL | re.MULTILINE)\n",
    "    if len(search) > 0:\n",
    "        comentarios[codigo] = search\n",
    "for codigo in codigos:\n",
    "    get_comentarios(comentarios, codigo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_image = []\n",
    "with open('./pratique/contain_image.json', 'r', encoding='utf-8') as f:\n",
    "    contain_image = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurações globais para os gráficos\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "# Convertendo os dicionários em DataFrames para facilitar a análise\n",
    "results_df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "info_df = pd.DataFrame.from_dict(info, orient=\"index\")\n",
    "\n",
    "# Unindo os dois DataFrames\n",
    "data = results_df.join(info_df)\n",
    "\n",
    "# Filtrando questões válidas (sem erro de compilação, TLE ou MLE)\n",
    "valid_data = data[\n",
    "    (data[\"comp\"] == True) &\n",
    "    (~data.index.isin(list_TLE)) &\n",
    "    (~data.index.isin(list_MLE))\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cumulative Distribution Function (CDF) das pontuações\n",
    "plt.figure()\n",
    "sns.ecdfplot(data=valid_data, x=\"pontuacao\", stat=\"proportion\")\n",
    "plt.title(\"Função de Distribuição Acumulada das Pontuações\")\n",
    "plt.xlabel(\"Pontuação (%)\")\n",
    "plt.ylabel(\"Proporção Acumulada\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Porcentagens de acertos por quantidade de subtarefas\n",
    "valid_data[\"subtask_group\"] = pd.cut(\n",
    "    valid_data[\"n_subtarefas\"],\n",
    "    bins=[0, 3, 6, 10, np.inf],\n",
    "    labels=[\"1-3\", \"4-6\", \"7-10\", \"11+\"]\n",
    ")\n",
    "valid_data[\"accuracy\"] = valid_data[\"subtarefas100\"] / valid_data[\"n_subtarefas\"] * 100\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=valid_data, x=\"subtask_group\", y=\"accuracy\", palette=\"Blues\")\n",
    "plt.title(\"Porcentagem de Acertos por Quantidade de Subtarefas\")\n",
    "plt.xlabel(\"Grupo de Subtarefas\")\n",
    "plt.ylabel(\"Porcentagem de Acertos (%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Comparativo entre questões com e sem imagens\n",
    "data[\"has_image\"] = data.index.isin(contain_image)\n",
    "grouped_image = data.groupby(\"has_image\").agg(\n",
    "    pontuacao_media=(\"pontuacao\", \"mean\"),\n",
    "    erros=(\"comp\", lambda x: (~x).sum()),\n",
    "    TLE=(\"tempo\", lambda x: x.isin(list_TLE).sum()),\n",
    "    MLE=(\"mem\", lambda x: x.isin(list_MLE).sum())\n",
    ").reset_index()\n",
    "\n",
    "plt.figure()\n",
    "grouped_image.plot(kind=\"bar\", x=\"has_image\", stacked=True, color=[\"#4c72b0\", \"#55a868\", \"#c44e52\"])\n",
    "plt.title(\"Comparativo entre Questões com e sem Imagens\")\n",
    "plt.xlabel(\"Contém Imagem\")\n",
    "plt.ylabel(\"Média e Erros\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4) Pontuação média por edição, nível e fase\n",
    "data[\"edition\"] = data.index.str.split(\"_\").str[0]\n",
    "data[\"level\"] = data.index.str.split(\"_\").str[1]\n",
    "data[\"phase\"] = data.index.str.split(\"_\").str[2]\n",
    "\n",
    "grouped_edition = data.groupby([\"edition\", \"level\", \"phase\"])[\"pontuacao\"].mean().unstack()\n",
    "\n",
    "plt.figure()\n",
    "grouped_edition.plot(kind=\"bar\", cmap=\"viridis\")\n",
    "plt.title(\"Pontuação Média por Edição, Nível e Fase\")\n",
    "plt.xlabel(\"Edição, Nível e Fase\")\n",
    "plt.ylabel(\"Pontuação Média\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5) Porcentagem de TLE, MLE e erros de compilação por edição, nível e fase\n",
    "verdict_counts = data.groupby([\"edition\", \"level\", \"phase\"]).apply(\n",
    "    lambda x: pd.Series({\n",
    "        \"TLE\": x.index.isin(list_TLE).sum(),\n",
    "        \"MLE\": x.index.isin(list_MLE).sum(),\n",
    "        \"Erro de Compilação\": (~x[\"comp\"]).sum()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "verdict_counts_melted = verdict_counts.melt(\n",
    "    id_vars=[\"edition\", \"level\", \"phase\"],\n",
    "    value_vars=[\"TLE\", \"MLE\", \"Erro de Compilação\"],\n",
    "    var_name=\"Veredito\",\n",
    "    value_name=\"Quantidade\"\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(data=verdict_counts_melted, x=\"edition\", y=\"Quantidade\", hue=\"Veredito\", palette=\"Set2\")\n",
    "plt.title(\"Porcentagem de Vereditos por Edição, Nível e Fase\")\n",
    "plt.xlabel(\"Edição, Nível e Fase\")\n",
    "plt.ylabel(\"Porcentagem\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6) Percentual de pontuação 100 por edição, nível e fase\n",
    "accepted_counts = data.groupby([\"edition\", \"level\", \"phase\"]).apply(\n",
    "    lambda x: (x.index.isin(list_accepted).sum() / len(x)) * 100\n",
    ").reset_index(name=\"Percentual de Pontuação 100\")\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(data=accepted_counts, x=\"edition\", y=\"Percentual de Pontuação 100\", hue=\"level\", palette=\"coolwarm\")\n",
    "plt.title(\"Percentual de Pontuação 100 por Edição, Nível e Fase\")\n",
    "plt.xlabel(\"Edição, Nível e Fase\")\n",
    "plt.ylabel(\"Percentual (%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7) Relação entre tamanho do enunciado/entradas/saídas e pontuações/vereditos\n",
    "plt.figure()\n",
    "sns.pairplot(data, vars=[\"len_enunciado\", \"len_entrada\", \"len_saida\", \"pontuacao\"], hue=\"comp\", palette=\"husl\")\n",
    "plt.suptitle(\"Relação entre Tamanho do Enunciado/Entradas/Saídas e Pontuações\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envIC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
